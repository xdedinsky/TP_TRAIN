import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import time

from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix
from xgboost import XGBClassifier
from scipy.stats import randint, uniform

# 1. NaÄÃ­tanie dÃ¡t
print("â³ NaÄÃ­tavam dÃ¡ta...")
data = pd.read_csv("../preprocessed_data.csv").drop_duplicates()

# 2. KÃ³dovanie pouÅ¾Ã­vateÄ¾ov
print("ğŸ”¢ Label encoding...")
le = LabelEncoder()
data["userid"] = le.fit_transform(data["userid"])

# 3. Rozdelenie na X a y
X = data.drop("userid", axis=1)
y = data["userid"]

# 4. Rozdelenie na trÃ©novacie a testovacie dÃ¡ta
print("âœ‚ï¸ RozdeÄ¾ujem dÃ¡ta...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, stratify=y, random_state=42
)

# 5. Vytvorenie pipeline
print("ğŸ—ï¸ VytvÃ¡ram pipeline...")
pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('classifier', XGBClassifier(
        eval_metric='mlogloss',
        random_state=42,
        n_jobs=-1,
        tree_method='hist',
        enable_categorical=False
    ))
])

# 6. Hyperparametre
print("ğŸ” SpÃºÅ¡Å¥am RandomizedSearchCV...")
param_dist = {
    'classifier__n_estimators': randint(200, 2000),
    'classifier__max_depth': randint(3, 15),
    'classifier__learning_rate': uniform(0.005, 0.3),
    'classifier__subsample': uniform(0.5, 0.5),
    'classifier__colsample_bytree': uniform(0.5, 0.5),
    'classifier__gamma': uniform(0, 2),
    'classifier__reg_alpha': uniform(0, 2),
    'classifier__reg_lambda': uniform(0, 2),
    'classifier__min_child_weight': randint(1, 10),
}

# 7. TrÃ©novanie
random_search = RandomizedSearchCV(
    pipeline,
    param_distributions=param_dist,
    n_iter=300,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42,
    error_score='raise'
)

start_time = time.time()
print("â³ TrÃ©novanie mÃ´Å¾e trvaÅ¥ dlhÅ¡ie...")
random_search.fit(X_train, y_train)
print(f"\nâœ… TrÃ©novanie dokonÄenÃ© za {(time.time()-start_time)/60:.2f} minÃºt")
print(f"ğŸ“ˆ NajlepÅ¡ie parametre:\n{random_search.best_params_}")

# 8. Vyhodnotenie modelu
print("\nğŸ“Š Vyhodnocujem model...")
best_model = random_search.best_estimator_
y_pred = best_model.predict(X_test)
y_proba = best_model.predict_proba(X_test)

acc = accuracy_score(y_test, y_pred)
roc = roc_auc_score(y_test, y_proba, multi_class='ovr')

print(f"\nâœ… PresnosÅ¥: {acc:.5f}")
print(f"ğŸ¯ ROC AUC: {roc:.5f}")
print("\nğŸ“‹ Classification Report:")
print(classification_report(y_test, y_pred, digits=5))

# 9. Confusion matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()
